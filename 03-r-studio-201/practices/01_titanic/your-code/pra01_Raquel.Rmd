---
title: 'Minería de datos: mod01'
author: "Autor: Raquel Martín "
date: "noviembre 2020"
output:
  pdf_document:
    highlight: zenburn
    toc: yes
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

******
# Introducción
******

## Descripción de la PRÁCTICA a realizar
La prueba está estructurada en 1 ejercicio teórico/práctico y 1 ejercicio práctico que pide que se desarrolle la fase de preparación en un juego de datos.  
Deben responderse todos los ejercicios para poder superar la PRA.  

## Recursos
Para realizar esta práctica recomendamos la lectura de los siguientes documentos:  

* RStudio Cheat Sheet: Disponible en el aula Laboratorio de Minería de datos.  
* R Base Cheat Sheet: Disponible en el aula Laboratorio de Minería de datos.  

*****
# Enunciado  
******
Como ejemplo, trabajaremos con el conjunto de datos "Titanic" que recoge datos sobre el famoso crucero y sobre el que es fácil realizar tareas de clasificación predictiva sobre la variable "Survived".   

De momento dejaremos para las siguientes prácticas el estudio de algoritmos predictivos y nos centraremos por ahora en el estudio de las variables de una muestra de datos, es decir, haremos un trabajo descriptivo del mismo. 

Las actividades que llevaremos a cabo en esta práctica suelen enmarcarse en las fases iniciales de un proyecto de minería de datos y consisten en la selección de caraterísticas o variables y la preparación del los  datos para posteriormente ser consumido por un algoritmo.

Las técnicas que trabajaremos son las siguientes:  

1. Normalización  
2. Discretización  
3. Gestión de valores nulos  
4. Estudio de correlaciones  
5. Reducción de la dimensionalidad
6. Análisis visual del conjunto de datos  

******
# Ejemplo de estudio visual con el juego de datos Titanic
******

## Procesos de limpieza del conjunto de datos

Primer contacto con el conjunto de datos, visualizamos su estructura.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)

# Guardamos el conjunto de datos test y train en un único dataset
test <- read.csv("C:/Users/raque/Documents/GitHub/https---github.com-RaquelMartinDiaz-NEOLAND-DS2020-datalabs/data/titanic-test.csv",stringsAsFactors = FALSE)
train <- read.csv('C:/Users/raque/Documents/GitHub/https---github.com-RaquelMartinDiaz-NEOLAND-DS2020-datalabs/data/titanic-train.csv', stringsAsFactors = FALSE)

# Unimos los dos conjuntos de datos en uno solo
totalData <- bind_rows(train,test)
filas=dim(train)[1]

# Verificamos la estructura del conjunto de datos
str(totalData)
```

Trabajamos los atributos con valores vacíos.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estadísticas de valores vacíos
colSums(is.na(totalData))
colSums(totalData=="")

# Tomamos valor "C" para los valores vacíos de la variable "Embarked"
totalData$Embarked[totalData$Embarked==""]="C"

# Tomamos la media para valores vacíos de la variable "Age"
totalData$Age[is.na(totalData$Age)] <- mean(totalData$Age,na.rm=T)
```

Discretizamos cuando tiene sentido y en función de cada variable.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# ¿Con qué variables tendría sentido un proceso de discretización?
apply(totalData,2, function(x) length(unique(x)))

# Discretizamos las variables con pocas clases
cols<-c("Survived","Pclass","Sex","Embarked")
for (i in cols){
  totalData[,i] <- as.factor(totalData[,i])
}

# Después de los cambios, analizamos la nueva estructura del conjunto de datos
str(totalData)
```


## Procesos de análisis del conjunto de datos

Nos proponemos analizar las relaciones entre las diferentes variables del conjunto de datos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Visualizamos la relación entre las variables "sex" y "survival":
ggplot(data=totalData[1:filas,],aes(x=Sex,fill=Survived))+geom_bar()

# Otro punto de vista. Survival como función de Embarked:
ggplot(data = totalData[1:filas,],aes(x=Embarked,fill=Survived))+geom_bar(position="fill")+ylab("Frecuencia")

```

Obtenemos una matriz de porcentages de frecuencia.  
Vemos, por ejemplo que la probabilidad de sobrevivir si se embarcó en "C" es de un 55,88%

```{r echo=TRUE, message=FALSE, warning=FALSE}
t<-table(totalData[1:filas,]$Embarked,totalData[1:filas,]$Survived)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
t
```

Veamos ahora como en un mismo gráfico de frecuencias podemos trabajar con 3 variables: Embarked, Survived y Pclass.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Ahora, podemos dividir el gráfico de Embarked por Pclass:
ggplot(data = totalData[1:filas,],aes(x=Embarked,fill=Survived))+geom_bar(position="fill")+facet_wrap(~Pclass)
```

Comparemos ahora dos gráficos de frecuencias: Survived-SibSp y Survived-Parch

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survivial como función de SibSp y Parch
ggplot(data = totalData[1:filas,],aes(x=SibSp,fill=Survived))+geom_bar()
ggplot(data = totalData[1:filas,],aes(x=Parch,fill=Survived))+geom_bar()
# Vemos como las forma de estos dos gráficos es similar. Este hecho nos puede indicar presencia de correlaciones altas.
```

Veamos un ejemplo de construcción de una variable nueva: Tamaño de familia

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Construimos un atributo nuevo: family size.
totalData$FamilySize <- totalData$SibSp + totalData$Parch +1;
totalData1<-totalData[1:filas,]
ggplot(data = totalData1[!is.na(totalData[1:filas,]$FamilySize),],aes(x=FamilySize,fill=Survived))+geom_histogram(binwidth =1,position="fill")+ylab("Frecuencia")

# Observamos como familias de entre 2 y 6 miembros tienen más del 50% de posibilidades de supervivencia.  
```

Veamos ahora dos gráficos que nos compara los atributos Age y Survived.  
Observamos como el parámetro position="fill" nos da la proporción acumulada de un atributo dentro de otro

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survival como función de age:
ggplot(data = totalData1[!(is.na(totalData[1:filas,]$Age)),],aes(x=Age,fill=Survived))+geom_histogram(binwidth =3)
ggplot(data = totalData1[!is.na(totalData[1:filas,]$Age),],aes(x=Age,fill=Survived))+geom_histogram(binwidth = 3,position="fill")+ylab("Frecuencia")
```



******
# Ejercicios
******

## Ejercicio 1: 

Estudia los tres casos siguientes y contesta, de forma razonada la  pregunta que se realiza:

* Disponemos de un conjunto de variables referentes a vehículos, tales como la marca, modelo, año de matriculación, etc. También se dispone del precio al que se vendieron. Al poner a la venta a un nuevo vehículo, se dispone de las variables que lo describen, pero se desconoce el precio. ¿Qué tipo de algoritmo se debería aplicar para predecir de forma automática el precio?

* En un almacén de naranjas se tiene una máquina, que de forma automática obtiene un conjunto de variables de cada naranja, como su tamaño, acidez, grado maduración, etc. Si se desea estudiar las naranjas por tipos, según las variables obtenidas, ¿qué tipo de algoritmo es el más adecuado?

* Un servicio de música por internet dispone de los historiales de audición de sus clientes: Qué canciones y qué grupos eligen los clientes a lo largo del tiempo de sus escuchas. La empresa desea crear un sistema  que proponga la siguiente canción y grupo en función de la canción que se ha escuchado antes. ¿Qué tipo de algoritmo es el más adecuado?

### Respuesta 1:
> Escribe aquí la respuesta a la pregunta

No termino de entender si quieres que investiguemos acerca de algoritmos de predicción o lo que haríamos. 
1.1.- En el primer caso referente a los vehículos, estudiaría primero la variable del precio de compra inicial para ver si tengo NA. Si no tuviera, estudiaría la relación con el resto de variables, para ver la relación con el modelo, el año de matriculación, la marca, etc. Luego buscaría información acerca de la pérdida de valor de un coche con el paso del tiempo, el kilometraje, etc. Y a partir de ahí crearía una nueva variable con el precio de venta relacionada con los datos anteriormente objetinos. Si la variable precio de compra inicial tuviera NA primero comprobaría si tengo datos duplicados con el resto de variables que sí tengan el precio de compra. Si no fuera el caso, revisaría por modelos coches similares para estimar el precio de compra.



## Ejercicio 2:  
A partir del conjunto de datos disponible en el siguiente enlace http://archive.ics.uci.edu/ml/datasets/Adult , realiza un estudio tomando como propuesta inicial al que se ha realizado con el conjunto de datos "Titanic". Amplia la propuesta generando nuevos indicadores o solucionando otros problemas expuestos en el módulo 2. Explica el proceso que has seguido, qué conocimiento obtienes de los datos, qué objetivo te has fijado y detalla los pasos, técnicas usadas y los problemas resueltos.

Nota: Si lo deseas puedes utilizar otro conjunto de datos propio o de algun repositorio open data siempre que sea similar en diversidad de tipos de variables al propuesto. 

### Respuesta 2:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos el juego de datos
datosAdult <- read.csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',stringsAsFactors = FALSE, header = FALSE)

# Nombres de los atributos
names(datosAdult) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hour-per-week","native-country","income")
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Redacta aquí el código R para el estudio del juego de datos Adult
# Primero voy a comprobar la estructura de datos de Adult.
str(datosAdult)
```
Tenemos 15 variables y 32561 observaciones. 

Comprobamos si hay datos NA.

```{r}
any(is.na(datosAdult))
```
No  tenemos datos vacíos en nuestras variables. 

Vemos las primeras filas de datosAdult. 

```{r}
head(datosAdult)

```
Vamos a analizar variable por variable. 

### Age

```{r}
unique(datosAdult$age)
```
```{r}
summary(datosAdult$age)
```
La edad mínima son 17 años y la máxima 90, con una edad media de 38 años. 

### Workclass
```{r}
unique(datosAdult$workclass)
```

Antes hemos visto que no hay valores NA pero sí que vemos que en Workclass hay valores desconocidos "?". 
Calculamos la tabla de frecuencias.

```{r}
table(datosAdult$workclass)
```

Hay 1836 valores desconocidos. Vamos a categorizar la variable unificando el tipo de empleo por gente que trabaja para el gobierno, autónomos, sector privado y vamos a unificar la gente que nunca ha trabajado con la que no cobra y los desconocidos. 

```{r}
self_emp <- c(" Self-emp-inc", " Self-emp-not-inc")
no_work <- c(" Never-worked", " Without-pay", " ?")
gobierno <- c(" Federal-gov", " Local-gov", " State-gov")
```

Y creamos una función para categorizarla:

```{r}
trabajos <- function(trabajo){
  if(trabajo %in% self_emp){
    return("self_emp")
  }else if(trabajo %in% no_work){
    return("no_work")
  }else if(trabajo %in% gobierno){
    return("gobierno")
  } else{
    return(trabajo)
  }
}
```

E incluimos las categorías en la variable:

```{r}
datosAdult$workclass<- sapply(datosAdult$workclass, trabajos)
```

```{r}
unique(datosAdult$workclass)
```

Vamos a ver la relación entre la edad y el tipo de trabajo.

```{r}
ggplot(data=datosAdult[1:filas,],aes(x=age,fill=workclass))+geom_bar()

```
Vamos a ver ahora la matriz de porcentajes de frecuencias de Age y Workclass. 

```{r}
t<-table(datosAdult[1:filas,]$age,datosAdult[1:filas,]$workclass)
for (i in 1:dim(t)[1]){
    t[i,]<-round(t[i,]/sum(t[i,])*100,2)
}
t
```
### fnlgt

Esta variable es el final weght, es decir, el número de personas que el censo estima que representa. Esta variable sería interesante a la hora de ver el peso real de una observación. 

```{r}
summary(datosAdult$fnlwgt)
```
Vemos que la media representación es de 189.778 pero que el mínimo es 12.285 y el máximo 1.484.705, por lo que hay observaciones cuyo peso es muy superior al de otras.

También vemos que la mediana es 178.356, que el Q1 es 117.827 y el Q3 237.051. El rango intercuantílico es 119.224. Teniendo en cuenta que un valor atípico extremo es aquel que dista 3 veces el rango intercuantílico por debajo de Q1 o por encima de Q3; es decir, aquel que esté por debajo o por encima de Q1 y Q3 respectivamente en 357.672.

Vamos a verlo visualmente. 

```{r}
plot(x= datosAdult$fnlwgt, col ="blue")
```
Con el gráfico vemos que hay outliers por arriba. Por abajo no porque sería una cifra negativa y nuestro umbral mínimo es 0. 

Vamos a ver también una caja de bigotes:

```{r}
boxplot(datosAdult$fnlwgt,
        main = "fnlwgt",
        boxwex = 0.5, col = "red")
```

Calculamos por aquí el rango intercuantílico:

```{r}
RIC= quantile(datosAdult$fnlwgt, prob=c(0.25, 0.75))
RIC
```

```{r}
Valor_outliers = (quantile(datosAdult$fnlwgt, prob=c(0.75)) - quantile(datosAdult$fnlwgt, prob=c(0.25))) * 3
Valor_outliers
```
Con lo cual vamos a ver cuántos son esos los valores por encima de esa cantidad de la variable ya que nos desvirtúan el estudio y vemos si podemos eliminarlos o los reemplazamos. Para ello creamos un df1 filtrando los datos que no serían outliers de fnlwgt.


```{r}
df1 <- filter(datosAdult, fnlwgt < "357672")
```

Y vemos la variable fnlwgt en nuestro dataframe filtrado gráficamente. 


```{r}
boxplot(df1$fnlwgt,
        main = "fnlwgt",
        boxwex = 0.5, col = "red")
```

Vemos que sigue habiendo outliers pero serían valores atípicos leves ya que los extremos los hemos eliminado en el dataframe df1.


### Marital-status

Vamos a categorizar ahora la variable marital- status.

```{r}
table(df1$`marital-status`)
```

```{r}
casado <- c(" Married-AF-spouse", " Married-civ-spouse", "Married-spouse-absent")
no.casado <- c(" Divorced", " Separated", " Widowed")
nunca.casado <- c(" Never-married")
```

Mediante una función cambiamos las categorías.

```{r}
estado.civil <- function(estado){
  if(estado %in% casado){
    return("casado")
  }else if(estado %in% no.casado){
    return("no.casado")
  }else{
    return("nunca.casado")
  }
}
```
```{r}
df1$`marital-status`<- sapply(df1$`marital-status`, estado.civil)
```

Comprobamos de nuevo la variable. 

```{r}
table(df1$`marital-status`)
```

Vamos a verla gráficamente con edad. 

```{r}
unique(df1$`marital-status`)
```

```{r}
ggplot(data=df1[1:filas,],aes(x=age,fill=`marital-status`))+geom_bar()
```

Y por sexo:

```{r}
ggplot(data=df1[1:filas,],aes(x=sex,fill=`marital-status`))+geom_bar()
```

### Occupation 

Vamos a categorizar la variable occupation 

```{r}
unique(df1$occupation)
```

Hay datos de origen desconocido. Vamos a ver la tabla de frecuencias.


```{r}
table(df1$occupation)
```

Hay 1456 profesiones de orgien desconocido. También vemos que hay 8 que pertenecen a las fuerzas armadas, que vamos a unir con los de origen desconocido. 

```{r}
White_collar <- c(" Adm-clerical", " Exec-managerial", " Tech-support")
Desconocido <- c(" Armed-Forces", " Unknown")
Blue_collar <- c(" Craft-repair", " Farming-fishing", " Handlers-cleaners", " Machine-op-inspct", " Transport-moving")
Servicios <- c(" Other-service", " Priv-house-serv")
Profesional <- c(" Prof-specialty")
Ventas <- c(" Sales")
```

```{r}
ocupaciones <- function(ocupacion){
  if(ocupacion %in% White_collar){
    return("White_collar")
  }else if(ocupacion %in% Ventas){
    return("Sales")
  }else if(ocupacion %in% Blue_collar){
    return("Blue_collar")
  }else if(ocupacion %in% Servicios){
    return("Servicios")
  }else if(ocupacion %in% Profesional){
    return("Profesional")
  }else{return("Desconocido")}
}
```

```{r}
df1$occupation<- sapply(df1$occupation, ocupaciones)
```

```{r}
table(df1$occupation)
```

Ya tenemos categorizada nuestra variable. Vamos a ver gráficamente la relación entre edad y la ocupación, 

```{r}
ggplot(data=df1[1:filas,],aes(x=age,fill=occupation))+geom_bar()
```

Y por sexo.

```{r}
ggplot(data=df1[1:filas,],aes(x=sex,fill=`marital-status`))+geom_bar()
```
Vamos a ver también la relación entre ocupación y workclass.

```{r}
ggplot(data=df1[1:filas,],aes(x=occupation,fill=workclass))+geom_bar()
```

Vemos que la mayoría de blue collar trabajan para la empresa privada, seguidos de autónomos y por último una pequeña cantidad trabaja para el gobierno. De origen desconocido la mayoría no trabajan, teniendo en cuenta que hemos incluido aquí una gran cantidad de datos de los que no sabíamos de dónde salían es importante ver que realmente es gente que en su mayoría no tiene trabajo. Con respecto a las ventas vemos que o son autónomos o trabajan en el sector privado, pero no trabajan para el gobierno ni están sin empleo. En el sector servicios hay una pequeña cantidad de trabajadores autónomos, algunos trabajan para el gobierno y la mayoría lo hacen en el sector privado. Y los white collars trabajan principalmente en el sector privado, y aparentemente la misma canditdad trabaja para el gobierno o es autonoma, pero tampoco están desempleados. 


### native country

Vamos a ver los paises y a categorizar la variable

```{r}
unique(df1$`native-country`)
```

```{r}
boxplot(df1$fnlwgt,
        main = "native-country",
        boxwex = 0.5, col = "red")
```
Vemos que hay algunos datos outliers. Vamos a ver la tabla de frecuencias y creamos las distintas categorías, así veremos si sigue habiendo outliers o no. 

```{r}
table(df1$`native-country`)
```


```{r}
Asia <- c(" Cambodia", " China", " Hong", " India", " Iran", " Japan", " Laos", " Philippines", " Taiwan", " Thailand", " Vietnam")
Nor_America <- c(" Canada", " United-States")
Sur_America <- c(" Columbia", " Cuba", " Dominican-Republic", " Ecuador", " El-Salvador", " Guatemala", " Haiti", " Honduras", " Jamaica", " Mexico", " Nicaragua", " Outlying-US(Guam-USVI-etc", " Peru", " Puerto-Rico", " Trinidad&Tobago")
Europa <-c(" England", " France", " Germany", " Greece", " Holand-Netherlands", " Hungary", " Ireland", " Italy", " Poland", " Portugal", " Scotland", " Yugoslavia")
Otros <- c(" South", " ?")
```

```{r}
continente <-function(pais){
    if(pais %in% Asia){
      return("Asia")
    }else if(pais %in% Nor_America){
      return("Nor_America")
    }else if(pais %in% Sur_America){
      return("Sur_America")
    }else if(pais %in% Europa){
      return("Europa")
    }else{
      return("Otros")
    }
}

```

```{r}
df1$`native-country`<- sapply(df1$`native-country`, continente)

```

Volvemos a ver la tabla de frecuencias y la caja de bigotes.

```{r}
table(df1$`native-country`)
```

```{r}
boxplot(df1$fnlwgt,
        main = "native-country",
        boxwex = 0.5, col = "blue")
```
Sigue habiendo algunos datos outliers pero hay que tener en cuenta que la mayoría de nuestro data frame se concentra en norte américa. Vamos a ver los porcentajes. 

```{r}
prop.table(table(df1$`native-country`))
```


El 89,84% de los datos pertenecen a norte América, por lo que es lógico que existan outliers que, en este caso, no vamos a eliminar.


### income

La variable ingresos Income, solo diferencia entre menor o igual de 50k, no sabemos cuál es la moneda de referencia, y más de 50k. Vemos que el porcentaje de menor o igual de 50k es superior al de observaciones que cobran más de esa cantidad:

```{r}
round(prop.table(table(df1$income))*100, 2)
```
Exactamente un 75.92% de las observaciones cobran menos o igual de 50k y un 24.08% cobra más.

Vamos a ver por continentes, cuáles tienes mayores ingresos.

```{r}
table(df1$`native-country`, df1$income)
```

Y en porcentajes

```{r}
A <- round(prop.table(table(df1$`native-country`, df1$income))*100,2)
A
```

Vamos a verlo gráficamente.

```{r}
ggplot(data=df1[1:filas,],aes(x=`native-country`, fill= income ))+geom_bar()
```

Vemos que como la mayoría de datos están recogidos en norte América, es complicado ver el resto de datos. 



